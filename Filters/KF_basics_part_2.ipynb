{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KF Basics - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilistic Generative Laws\n",
    "**1st Law**:\n",
    "The belief representting the state $x_{t}$, is conditioned on all past states, measurements and controls. This can be shown mathematically by the conditional probability shown below:\n",
    "\n",
    "$$p(x_{t} | x_{0:t-1},z_{1:t-1},u_{1:t})$$\n",
    "\n",
    "1) $z_{t}$ represents the **measurement**\n",
    "\n",
    "2) $u_{t}$ the **motion command**\n",
    "\n",
    "3) $x_{t}$ the **state** (can be the position, velocity, etc) of the robot or its environment at time t.\n",
    "\n",
    "\n",
    "'If we know the state $x_{t-1}$ and $u_{t}$, then knowing the states $x_{0:t-2}$, $z_{1:t-1}$ becomes immaterial through the property of **conditional Independance**'. The state $x_{t-1}$ introduces a conditional independance between $x_{t}$ and $z_{1:t-1}$, $u_{1:t-1}$\n",
    "\n",
    "Therefore the law now holds as:\n",
    "\n",
    "$$p(x_{t} | x_{0:t-1},z_{1:t-1},u_{1:t})=p(x_{t} | x_{t-1},u_{t})$$\n",
    "\n",
    "**2nd Law**:\n",
    "\n",
    "If $x_{t}$ is complete, then:\n",
    "\n",
    "$$p(z_{t} | x-_{0:t},z_{1:t-1},u_{1:t})=p(z_{t} | x_{t})$$\n",
    "\n",
    "$x_{t}$ is **complete** means that the past states, controls or measurements carry no additional information to predict future.\n",
    "\n",
    "$x_{0:t-1}$, $z_{1:t-1}$ and $u_{1:t}$ are **conditionally independant** of $z_{t}$ given $x_{t}$ of complete.\n",
    "\n",
    "The filter works in two parts:\n",
    "\n",
    "$\\bullet$  $p(x_{t} | x_{t-1},u_{t})\\rightarrow $**State Transition Probability**\n",
    "\n",
    "$\\bullet$  $p(z_{t} | x_{t}) \\rightarrow $**Measurement Probability**\n",
    "\n",
    "\n",
    "### Conditional dependance and independance example:\n",
    "\n",
    "**Independent but conditionally dependent**\n",
    "\n",
    "Let's say you flip two fair coins\n",
    "\n",
    "A - Your first coin flip is heads\n",
    "\n",
    "B - Your second coin flip is heads\n",
    "\n",
    "C - Your first two flips were the same\n",
    "\n",
    "\n",
    "A and B here are independent. However, A and B are conditionally dependent given C, since if you know C then your first coin flip will inform the other one.\n",
    "\n",
    "**Dependent but conditionally independent**\n",
    "\n",
    "A box contains two coins: a regular coin and one fake two-headed coin ((P(H)=1). I choose a coin at random and toss it twice. Define the following events.\n",
    "\n",
    "A= First coin toss results in an H.\n",
    "\n",
    "B= Second coin toss results in an H.\n",
    "\n",
    "C= Coin 1 (regular) has been selected.                                                             \n",
    "\n",
    "If we know A has occurred (i.e., the first coin toss has resulted in heads), we would guess that it is more likely that we have chosen Coin 2 than Coin 1. This in turn increases the conditional probability that B occurs. This suggests that A and B are not independent. On the other hand, given C (Coin 1 is selected), A and B are independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Rule:\n",
    "\n",
    "\n",
    "\n",
    "Posterior = $\\frac{Likelihood*Prior}{Marginal} $\n",
    "\n",
    "Here,\n",
    "\n",
    "**Posterior** = Probability of an event occuring based on certain evidence.\n",
    "\n",
    "**Likelihood** = How probable is the evidence given the event.\n",
    "\n",
    "**Prior** = Probability of the just the event occuring without having any evidence.\n",
    "\n",
    "**Marginal** = Probability of the evidence given all the instances of events possible.\n",
    "\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "1% of women have breast cancer (and therefore 99% do not).\n",
    "80% of mammograms detect breast cancer when it is there (and therefore 20% miss it).\n",
    "9.6% of mammograms detect breast cancer when it’s not there (and therefore 90.4% correctly return a negative result).\n",
    "\n",
    "We can turn the process above into an equation, which is Bayes’ Theorem. Here’s the equation:\n",
    "\n",
    "$\\displaystyle{\\Pr(\\mathrm{A}|\\mathrm{X}) = \\frac{\\Pr(\\mathrm{X}|\\mathrm{A})\\Pr(\\mathrm{A})}{\\Pr(\\mathrm{X|A})\\Pr(\\mathrm{A})+ \\Pr(\\mathrm{X | not \\ A})\\Pr(\\mathrm{not \\ A})}}$\n",
    "\n",
    "\n",
    "$\\bullet$Pr(A|X) = Chance of having cancer (A) given a positive test (X). This is what we want to know: How likely is it to have cancer with a positive result? In our case it was 7.8%.\n",
    "\n",
    "$\\bullet$Pr(X|A) = Chance of a positive test (X) given that you had cancer (A). This is the chance of a true positive, 80% in our case.\n",
    "\n",
    "$\\bullet$Pr(A) = Chance of having cancer (1%).\n",
    "\n",
    "$\\bullet$Pr(not A) = Chance of not having cancer (99%).\n",
    "\n",
    "$\\bullet$Pr(X|not A) = Chance of a positive test (X) given that you didn’t have cancer (~A). This is a false positive, 9.6% in our case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Filter Algorithm\n",
    "\n",
    "The basic filter algorithm is:\n",
    "\n",
    "for all $x_{t}$:\n",
    "\n",
    "1. $\\overline{bel}(x_t) = \\int p(x_t | u_t, x_{t-1}) bel(x_{t-1})dx$\n",
    "\n",
    "2. $bel(x_t) = \\eta p(z_t | x_t) \\overline{bel}(x_t)$\n",
    "\n",
    "end.\n",
    "\n",
    "\n",
    "$\\rightarrow$The first step in filter is to calculate the prior for the next step that uses the bayes theorem. This is the **Prediction** step. The belief, $\\overline{bel}(x_t)$, is **before** incorporating measurement($z_{t}$) at time t=t. This is the step where the motion occurs and information is lost because the means and covariances of the gaussians are added. The RHS of the equation incorporates the law of total probability for prior calculation.\n",
    "\n",
    "$\\rightarrow$ This is the **Correction** or update step that calculates the belief of the robot **after** taking into account the measurement($z_{t}$) at time t=t. This is where we incorporate the sensor information for the whereabouts of the robot. We gain information here as the gaussians get multiplied here. (Multiplication of gaussian values allows the resultant to lie in between these numbers and the resultant covariance is smaller.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bayes_filter.png\" title=\"Bayes filter\" width=\"50%\" height=\"50%\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
